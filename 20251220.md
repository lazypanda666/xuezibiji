# 机器学习

## 1. 基本术语

- **分类：预测离散标签的艺术**
  分类是监督学习的一个核心任务，其目标是通过学习输入数据与预定义标签之间的关系来预测离散标签

- **回归：预测连续值的科学**
  回归任务关注的是如何根据输入变量预测一个连续的数值

- **聚类：无监督学习中的分组专家**
  聚类是无监督学习的一种形式，其目标是将数据点划分为几个组或“簇”，使得同一簇内的数据点比其他簇的数据点更相似

- **降维：简化数据的魔法**

  降维是处理高维数据集的技术，通过减少随机变量的数量来简化模型，同时尽量保留原始数据的重要信息

## 2. 假设空间

- **核心定义**：假设空间是由**所有可能从输入特征映射到输出标签的函数或模型**构成的集合。它包含了学习算法可能考虑的所有“假设”。
- **特点与举例**：以判断“好瓜”为例，假设空间可以非常复杂，它既包括基于单一特征（如“色泽=青绿？”）的简单判断，也包括多个特征的复杂组合（如“如果色泽=青绿**且**根蒂=蜷缩，则是好瓜”），甚至更复杂的模型。这个空间可能是**有限的**，也可能是**无限的**。
- **根本作用**：明确了**机器学习的归纳过程，本质上就是从庞大的假设空间中，根据有限的训练数据，搜索并选择一个最匹配或最优假设**的过程。学习过程就是在对这个空间进行**探索和筛选**。

## 3. 归纳偏好

- **核心定义**：归纳偏好是学习算法自身所带入的一种**倾向性或价值观**，用于在**多个都能完美拟合训练数据的假设中做出选择**。没有这种偏好，学习结果将不唯一。
- **必要性**：由于假设空间通常很大，往往存在多个假设在训练集上表现一致（即“版本空间”）。为了得到一个确定的模型，并希望它能对未见数据做出好的预测，算法必须依赖某种预先设定的偏好进行抉择。
- **指导原则**：最著名的指导原则是**“奥卡姆剃刀”**，即优先选择**最简单（例如，形式更简短、参数更少）的假设**。文中通过西瓜例子对比了两种拟合方案（单一规则 vs. 复杂组合），说明偏好简单规则是更合理的选择。
- **核心结论**：**任何有效的机器学习算法都必须有其归纳偏好**，否则它只能随机选择，无法进行有效的学习与泛化。